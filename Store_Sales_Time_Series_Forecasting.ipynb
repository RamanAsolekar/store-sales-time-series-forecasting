{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sskfhj2LwvIi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKtlmlcEOaPx"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('train.csv', parse_dates=['date'])\n",
        "test = pd.read_csv('test.csv', parse_dates=['date'])\n",
        "stores = pd.read_csv('stores.csv')\n",
        "oil = pd.read_csv('oil.csv', parse_dates=['date'])\n",
        "holidays = pd.read_csv('holidays_events.csv', parse_dates=['date'])\n",
        "transactions = pd.read_csv('transactions.csv', parse_dates=['date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnD2R4xcOjU0",
        "outputId": "1540c6ca-a7fb-4f65-a243-fab74c121cdb"
      },
      "outputs": [],
      "source": [
        "print(f\"Training Range: {train.date.min()} to {train.date.max()}\")\n",
        "print(f\"Testing Range:  {test.date.min()} to {test.date.max()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNxtpDJjOm1l"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 5))\n",
        "# Group by date to see total sales across all stores\n",
        "daily_sales = train.groupby('date')['sales'].sum()\n",
        "plt.plot(daily_sales)\n",
        "plt.title(\"Total Sales History (Notice the spikes in December!)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y36SzkdYPRkv"
      },
      "outputs": [],
      "source": [
        "# --- 1. PREPARE THE DATA FRAME ---\n",
        "# Concatenate train and test sets to ensure consistent feature engineering.\n",
        "train_len = len(train)\n",
        "all_data = pd.concat([train, test], sort=False).reset_index(drop=True)\n",
        "all_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuAvDIt2Pusd"
      },
      "outputs": [],
      "source": [
        "# --- 2. DATE FEATURES (The \"Calendar\") ---\n",
        "# Feature Engineering: Decompose datetime into numerical features for tree-based modeling.\n",
        "all_data['date'] = pd.to_datetime(all_data['date'])\n",
        "all_data['year'] = all_data['date'].dt.year\n",
        "all_data['month'] = all_data['date'].dt.month\n",
        "all_data['day'] = all_data['date'].dt.day\n",
        "all_data['dayofweek'] = all_data['date'].dt.dayofweek # 0=Monday, 6=Sunday\n",
        "all_data['weekend'] = (all_data['dayofweek'] >= 5).astype(int) # 1 if Sat/Sun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1N9xVjMP061"
      },
      "outputs": [],
      "source": [
        "# Merge external economic data (Oil Prices).\n",
        "# Interpolate missing weekend values to maintain time-series continuity..\n",
        "oil = oil.set_index('date').resample('D').mean().interpolate(limit_direction='both').reset_index()\n",
        "all_data = pd.merge(all_data, oil, on='date', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQRKMj1qP6iq"
      },
      "outputs": [],
      "source": [
        "# B. Holidays (Simplify)\n",
        "# Binary holiday feature: focuses on effective days off rather than holiday names.\n",
        "holidays = holidays[holidays.transferred == False] # Ignore holidays that were moved\n",
        "holidays['is_holiday'] = 1\n",
        "# drop duplicates because some days have multiple holidays (e.g., Local + National)\n",
        "holiday_map = holidays[['date', 'is_holiday']].drop_duplicates(subset='date')\n",
        "all_data = pd.merge(all_data, holiday_map, on='date', how='left')\n",
        "all_data['is_holiday'] = all_data['is_holiday'].fillna(0) # Fill non-holidays with 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AuRk0NqKQEb5"
      },
      "outputs": [],
      "source": [
        "# --- 4. LAG FEATURES ---\n",
        "\n",
        "all_data['wages_day'] = ((all_data['day'] == 15) | (all_data['day'] == all_data['date'].dt.days_in_month)).astype(int)\n",
        "\n",
        "print(\"Feature Engineering Complete. Shape:\", all_data.shape)\n",
        "all_data.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T24dXLhLQgw2",
        "outputId": "73bdd31d-7d94-4a20-ef8f-bc784a44d664"
      },
      "outputs": [],
      "source": [
        "!pip install lightgbm\n",
        "import lightgbm as lgb\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_squared_log_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYGCZH7DQ7G4"
      },
      "outputs": [],
      "source": [
        "all_data = pd.merge(all_data, stores, on='store_nbr', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQlToo8bQmOO"
      },
      "outputs": [],
      "source": [
        "# --- 1. ENCODING (Text -> Numbers) ---\n",
        "# LabelEncoder for categories like 'Family' (Automotive, Grocery...)\n",
        "le = LabelEncoder()\n",
        "all_data['family'] = le.fit_transform(all_data['family'].astype(str))\n",
        "all_data['type'] = le.fit_transform(all_data['type'].astype(str))\n",
        "all_data['city'] = le.fit_transform(all_data['city'].astype(str))\n",
        "all_data['state'] = le.fit_transform(all_data['state'].astype(str))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ril4xqxRBbP"
      },
      "outputs": [],
      "source": [
        "train_data = all_data[all_data['date'] <= '2017-08-15']\n",
        "test_data = all_data[all_data['date'] > '2017-08-15']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIeTCvdLRDWq"
      },
      "outputs": [],
      "source": [
        "y = np.log1p(train_data['sales'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GM0q3c2WRFgc"
      },
      "outputs": [],
      "source": [
        "# Drop columns we can't use\n",
        "drop_cols = ['id', 'date', 'sales']\n",
        "X = train_data.drop(drop_cols, axis=1)\n",
        "X_test = test_data.drop(drop_cols, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xw4rND3RJIP"
      },
      "outputs": [],
      "source": [
        "# --- 3. HYBRID PART A: THE TREND (Linear Model) ---\n",
        "\n",
        "X['time_step'] = np.arange(len(X))\n",
        "X_test['time_step'] = np.arange(len(X), len(X) + len(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gd06jA3-RL2O"
      },
      "outputs": [],
      "source": [
        "# Use Ridge (Linear Regression with regularization)\n",
        "# Fit Ridge regression to capture the global linear trend\n",
        "model_linear = Ridge(alpha=0.5)\n",
        "model_linear.fit(X[['time_step']], y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfVqYCypROpo"
      },
      "outputs": [],
      "source": [
        "# Generate Trend Predictions\n",
        "pred_linear_train = model_linear.predict(X[['time_step']])\n",
        "pred_linear_test = model_linear.predict(X_test[['time_step']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRaxbJoRRRSN"
      },
      "outputs": [],
      "source": [
        "# Calculate Residuals (What the Linear model missed)\n",
        "# The Tree model will try to predict THESE residuals, not the raw sales.\n",
        "y_residuals = y - pred_linear_train\n",
        "\n",
        "print(\"Trend Model Trained.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TH8R3emRVdJ"
      },
      "outputs": [],
      "source": [
        "# Dataset for LGBM\n",
        "lgb_train = lgb.Dataset(X, y_residuals, categorical_feature=['store_nbr', 'family', 'city'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxAvSfPURZOT"
      },
      "outputs": [],
      "source": [
        "# Parameters (Tuned for this dataset)\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'rmse',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'learning_rate': 0.05,      # Low learning rate for precision\n",
        "    'num_leaves': 100,          # Complexity of trees\n",
        "    'feature_fraction': 0.8,    # Randomly select 80% of features (avoids overfitting)\n",
        "    'bagging_fraction': 0.7,    # Randomly select 70% of rows\n",
        "    'bagging_freq': 1,\n",
        "    'verbose': -1,\n",
        "    'seed': 42\n",
        "}\n",
        "\n",
        "print(\"Training LightGBM (Seasonality)...\")\n",
        "# train for 1000 rounds\n",
        "model_lgb = lgb.train(params, lgb_train, num_boost_round=1000)\n",
        "\n",
        "print(\"Hybrid Training Complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJlufY__RvUJ"
      },
      "outputs": [],
      "source": [
        "# 1. Predict with both models\n",
        "lgb_pred = model_lgb.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fH1HjNYUR22p"
      },
      "outputs": [],
      "source": [
        "# 2. Combine (Additive)\n",
        "# Final = Trend + Residuals\n",
        "final_log_pred = pred_linear_test + lgb_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4N1i2C7Rw3o"
      },
      "outputs": [],
      "source": [
        "# 3. Inverse Transform (Log -> Real Sales)\n",
        "# We must force negative predictions to 0 (Sales can't be negative)\n",
        "final_sales = np.expm1(final_log_pred)\n",
        "final_sales = np.clip(final_sales, 0, None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uF1toHXKR7QJ"
      },
      "outputs": [],
      "source": [
        "# 4. Create Submission File\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_data['id'],\n",
        "    'sales': final_sales\n",
        "})\n",
        "\n",
        "submission.to_csv('submission_hybrid.csv', index=False)\n",
        "print(\"Submission Ready! This uses a Detrended-Hybrid approach.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
